<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Crowdstream â€“ Synthesized Co-Creation</title>
  <style>
    body {
      font-family: sans-serif;
      margin: 40px auto;
      max-width: 800px;
      line-height: 1.6;
    }
    h1, h2 {
      text-align: center;
    }
    img {
      max-width: 100%;
      display: block;
      margin: 30px auto;
    }
  </style>
</head>
<body>

  <h1>Crowdstream</h1>
  <p style="text-align: center;">Synthesized Co-Creation of Music with AI + Audience</p>

  <img src="https://www.columbia.edu/~xig2000/sintesisColectiva/media/diagramaDji.jpg" alt="Crowdstream Diagram">

  <h2>1. Sensing the Audience</h2>
  <p>
    Using computer vision and audio sensing, Crowdstream interprets crowd reactions â€” facial expressions, motion, sound levels â€” to understand emotional feedback in real time.
  </p>

  <h2>2. Generating Music</h2>
  <p>
    AI tools generate or remix music dynamically based on audience input and environmental cues, creating an adaptive and expressive musical experience.
  </p>

  <h2>3. Audience as Composer</h2>
  <p>
    Listeners arenâ€™t just passive â€” their presence, reactions, and inputs help shape the music. Crowdstream treats the audience as co-creators in the artistic process.
  </p>

  <p style="text-align: center;">
    ðŸ‘‰ <a href="https://github.com/timmd-9216/crowdstream" target="_blank">View the Code on GitHub</a>
  </p>

</body>
</html>